{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVVCpswveYrZ"
      },
      "source": [
        "# **Art_Amp-XL In Context Lora to enhance Lineart Image for Light Novel**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0XGONPiedPk"
      },
      "outputs": [],
      "source": [
        "!pip install diffusers transformers accelerate safetensors huggingface_hub opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBzFQJxBftu0"
      },
      "outputs": [],
      "source": [
        "# Download the required files\n",
        "!wget https://huggingface.co/kataragi/controlnetXL_line2color/resolve/main/controlnetXL_line2colorV2-fp16.safetensors -O controlnetXL_line2colorV2-fp16.safetensors\n",
        "!wget https://huggingface.co/kataragi/controlnetXL_line2color/resolve/main/controlnetXL_line2colorV2-lora.safetensors -O controlnetXL_line2colorV2-lora.safetensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCRLd7hbj4MN"
      },
      "outputs": [],
      "source": [
        "!wget https://huggingface.co/kataragi/controlnetXL_line2color/resolve/main/model_index.json -O model_index.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCSfsRNoe_8r"
      },
      "outputs": [],
      "source": [
        "from diffusers import StableDiffusionXLPipeline, ControlNetModel\n",
        "from safetensors.torch import load_file\n",
        "from transformers import CLIPTokenizer, CLIPTextModel\n",
        "import torch\n",
        "from PIL import Image\n",
        "\n",
        "# Load ControlNet weights manually\n",
        "controlnet_weights_path = \"./controlnetXL_line2colorV2-fp16.safetensors\"\n",
        "controlnet_state_dict = load_file(controlnet_weights_path)\n",
        "\n",
        "# Initialize ControlNet model\n",
        "controlnet = ControlNetModel.from_config(\"./model_index.json\")\n",
        "controlnet.load_state_dict(controlnet_state_dict)\n",
        "\n",
        "# Convert ControlNet to float16 and move to GPU\n",
        "controlnet = controlnet.to(torch.float16).to(\"cuda\")\n",
        "\n",
        "# Initialize the SDXL pipeline with ControlNet\n",
        "pipeline = StableDiffusionXLPipeline.from_pretrained(\n",
        "    \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "\n",
        "# Add ControlNet to the pipeline\n",
        "pipeline.controlnet = controlnet\n",
        "pipeline.to(\"cuda\")\n",
        "\n",
        "# Load tokenizer and text encoder for embedding generation\n",
        "tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "text_encoder = CLIPTextModel.from_pretrained(\"openai/clip-vit-large-patch14\").to(\"cuda\").eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cqao10ieeKo"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess the line art image\n",
        "lineart_path = \"/content/art4.png\"  # Path to your uploaded line art\n",
        "lineart_image = Image.open(lineart_path).convert(\"RGB\")\n",
        "\n",
        "# Resize the image to match ControlNet's input size\n",
        "lineart_image = lineart_image.resize((1024, 1024))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysKuiaineh1H"
      },
      "outputs": [],
      "source": [
        "# Define the prompts\n",
        "#prompt = \"Colorize this line art in vibrant anime style with smooth textures and detailed shading.\"\n",
        "prompt = \"Colorize this anime character lineart with colorful style.\"\n",
        "#prompt = \"Colorize this line art in vibrant anime style with smooth textures and detailed shading.\"\n",
        "negative_prompt = \"Blurry, low-quality, unrealistic colors.\"\n",
        "\n",
        "# Tokenize the prompts\n",
        "prompt_tokens = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
        "negative_prompt_tokens = tokenizer(negative_prompt, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
        "\n",
        "# Generate embeddings\n",
        "text_embeds = text_encoder(prompt_tokens).last_hidden_state\n",
        "negative_text_embeds = text_encoder(negative_prompt_tokens).last_hidden_state\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDTuUBwZptdx"
      },
      "outputs": [],
      "source": [
        "# Define generation settings\n",
        "guidance_scale = 7.5  # Adjust for prompt adherence\n",
        "num_inference_steps = 100\n",
        "\n",
        "# Generate the colorized image\n",
        "result = pipeline(\n",
        "    prompt=prompt,\n",
        "    negative_prompt=negative_prompt,\n",
        "    image=lineart_image,  # Pass the preprocessed image\n",
        "    num_inference_steps=num_inference_steps,\n",
        "    guidance_scale=guidance_scale,\n",
        "    added_cond_kwargs={\n",
        "        \"text_embeds\": text_embeds,\n",
        "        \"negative_text_embeds\": negative_text_embeds,\n",
        "    },\n",
        ").images[0]\n",
        "\n",
        "# Save and display the result\n",
        "output_path = \"colorized_lineart3.png\"\n",
        "result.save(output_path)\n",
        "result.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
